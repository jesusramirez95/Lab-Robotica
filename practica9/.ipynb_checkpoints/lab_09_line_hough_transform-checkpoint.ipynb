{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Universidad de Monterrey\n",
    "\n",
    "### División de Ingenierías\n",
    "\n",
    "#### Lab - Robotics\n",
    "\n",
    "Lab 9: Hough Transform for line detection\n",
    "Authors: Alberto Jasiel Herrera (518836), Jesús Alejandro Ramíŕez (513026) y Kassandra Ibarra (323936)\n",
    "\n",
    "#### Introducción\n",
    "La detección de lineas es una de las herramientas más útiles en los sistemas de visión computacional, siempre que requerimos visualizar nuestro entorno tenemos que detectar los objetos que hay en él. La práctica pasada vimos como detectar bordes, pero la detección de bordes no es útil por si sola, más bien es un paso previo a la aplicación de otros métodos como la detección de líneas.\n",
    "\n",
    "#### Objetivo \n",
    "El objetivo de esta práctica es aprender a detectar las lineas y circulos dentro de una imagen a través del uso de la transformación de Hough. Esto con el objetivo de adquirir nuevas herramientas para poder realizar un análisis más profundo al momento de procesar imágenes para detectar objetos específicos. \n",
    "\n",
    "#### Materiales \n",
    "Raspberry PI 3\n",
    "Pantalla y cable HDMI para visualizar la raspberry.\n",
    "Además, la Raspberry debe contar con el software pedido al inicio del laboratorio (opencv, python 3.5, Jupyter, ssh, entre otros).\n",
    "\n",
    "#### Procedimiento \n",
    "\n",
    "##### Transformada Hough\n",
    "En esta parte de la práctica se analizará el uso de las transformadas de Hough que son utilizadas para la detección de líneas en una imagen. La transformada de Hough es un modelo paramétrico basado en una técnica en la que el modelo puede representar clases de instancias en las que cada uno tiene un valor determinado. \n",
    "\n",
    "Para detectar líneas en imágenes, la transformada Hough se basa en los puntos de imagen que pertenecen a los bordes. Recordemos que aprendimos  cómo extraer los bordes utilizando los operadores Sobel, Roberts, Scharr y Prewitt\n",
    "\n",
    "\n",
    "##### Voting\n",
    " \n",
    "En esta sección aprenderemos sobre el término Voting que es un enfoque general donde las características votan por todos los modelos que son compatibles con él. Una de las ventajas de utilizar este tipo de técnicas es que son muy robustas y no son sensibles a los valores atípicos por lo que el ruido no es un problema para este tipo de técnicas. \n",
    "Cuando se ajusta una línea a una serie de puntos como un borde, para esto se deben considerar algunos aspectos como: \n",
    "¿cuantos puntos pertenecen a la línea?\n",
    "¿Cuantos estan en la imagen?\n",
    "¿cuales puntos pertenecen a cada línea?\n",
    "para saber esto es por lo que usamos una transformada de Hough en la que cada punto de un borde vota por una línea compatible y busca las líneas con mayoría de votos.\n",
    "\n",
    "##### Espacio Hough\n",
    "Para comprender mejor como es que funciona una transformada de Hough. para comenzar debemos de tener una linea con parametros m0 y b0 que sera mapeada en el espacio de Houg como se muestra a continuacion:\n",
    "![title](i1.svg)\n",
    "\n",
    "ahora siguiendo un principio de dualidad podemos asumir que si tenemos un punto con valores x0 y y0 se puede obtener una línea en el espacio de Hough como se muestra a continuación:\n",
    "\n",
    "![title](i2.svg)\n",
    "![title](i3.svg)\n",
    "\n",
    "##### Detección de líneas usando OpenCV\n",
    "A continuación se muestra el código utilizado para la detección de las líneas de la carretera:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\tline_detection_using_hough_transform.py\n",
    "\n",
    "\tauthor: Kassandra Ibarra, Jesus Ramirez y Alberto Herrera\n",
    "\tuniversidad de monterrey\n",
    "\"\"\"\n",
    "\n",
    "# import required libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "import math\n",
    "# select a region of interest\n",
    "\n",
    "def draw_lines(img,lines):\n",
    "    # In case of error, don't draw the line\n",
    "\tdraw_right = True\n",
    "\tdraw_left = True\n",
    "    \n",
    "    # Find slopes of all lines\n",
    "    # But only care about lines where abs(slope) > slope_threshold\n",
    "\tslope_threshold = 0.5\n",
    "\tslopes = []\n",
    "\tnew_lines = []\n",
    "\tfor line in lines:\n",
    "\t\tx1, y1, x2, y2 = line[0]  # line = [[x1, y1, x2, y2]]\n",
    "        \n",
    "        # Calculate slope\n",
    "\t\tif x2 - x1 == 0.:  # corner case, avoiding division by 0\n",
    "\t\t\tslope = 999.  # practically infinite slope\n",
    "\t\telse:\n",
    "\t\t\tslope = (y2 - y1) / (x2 - x1)\n",
    "            \n",
    "        # Filter lines based on slope\n",
    "\t\tif abs(slope) > slope_threshold:\n",
    "\t\t\tslopes.append(slope)\n",
    "\t\t\tnew_lines.append(line)\n",
    "        \n",
    "\tlines = new_lines\n",
    "    \n",
    "    # Split lines into right_lines and left_lines, representing the right and left lane lines\n",
    "    # Right/left lane lines must have positive/negative slope, and be on the right/left half of the image\n",
    "\tright_lines = []\n",
    "\tleft_lines = []\n",
    "\tfor i, line in enumerate(lines):\n",
    "\t\tx1, y1, x2, y2 = line[0]\n",
    "\t\timg_x_center = img.shape[1] / 2  # x coordinate of center of image\n",
    "\t\tif slopes[i] > 0 and x1 > img_x_center and x2 > img_x_center:\n",
    "\t\t\tright_lines.append(line)\n",
    "\t\telif slopes[i] < 0 and x1 < img_x_center and x2 < img_x_center:\n",
    "\t\t\tleft_lines.append(line)\n",
    "            \n",
    "    # Run linear regression to find best fit line for right and left lane lines\n",
    "    # Right lane lines\n",
    "\tright_lines_x = []\n",
    "\tright_lines_y = []\n",
    "    \n",
    "\tfor line in right_lines:\n",
    "\t\tx1, y1, x2, y2 = line[0]\n",
    "        \n",
    "\t\tright_lines_x.append(x1)\n",
    "\t\tright_lines_x.append(x2)\n",
    "        \n",
    "\t\tright_lines_y.append(y1)\n",
    "\t\tright_lines_y.append(y2)\n",
    "        \n",
    "\tif len(right_lines_x) > 0:\n",
    "\t\tright_m, right_b = np.polyfit(right_lines_x, right_lines_y, 1)  # y = m*x + b\n",
    "\telse:\n",
    "\t\tright_m, right_b = 1, 1\n",
    "\t\tdraw_right = False\n",
    "        \n",
    "    # Left lane lines\n",
    "\tleft_lines_x = []\n",
    "\tleft_lines_y = []\n",
    "    \n",
    "\tfor line in left_lines:\n",
    "\t\tx1, y1, x2, y2 = line[0]\n",
    "        \n",
    "\t\tleft_lines_x.append(x1)\n",
    "\t\tleft_lines_x.append(x2)\n",
    "        \n",
    "\t\tleft_lines_y.append(y1)\n",
    "\t\tleft_lines_y.append(y2)\n",
    "        \n",
    "\tif len(left_lines_x) > 0:\n",
    "\t\tleft_m, left_b = np.polyfit(left_lines_x, left_lines_y, 1)  # y = m*x + b\n",
    "\telse:\n",
    "\t\tleft_m, left_b = 1, 1\n",
    "\t\tdraw_left = False\n",
    "    \n",
    "    # Find 2 end points for right and left lines, used for drawing the line\n",
    "    # y = m*x + b --> x = (y - b)/m\n",
    "\ty1 = 850\n",
    "\ty2 = 610\n",
    "    \n",
    "\tright_x1 = (y1 - right_b) / right_m\n",
    "\tright_x2 = (y2 - right_b) / right_m\n",
    "    \n",
    "\tleft_x1 = (y1 - left_b) / left_m\n",
    "\tleft_x2 = (y2 - left_b) / left_m\n",
    "    \n",
    "    # Convert calculated end points from float to int\n",
    "\ty1 = int(y1)\n",
    "\ty2 = int(y2)\n",
    "\tright_x1 = int(right_x1)\n",
    "\tright_x2 = int(right_x2)\n",
    "\tleft_x1 = int(left_x1)\n",
    "\tleft_x2 = int(left_x2)\n",
    "    \n",
    "    # Draw the right and left lines on image\n",
    "\tif draw_right:\n",
    "\t\tcv2.line(img, (right_x1, y1), (right_x2, y2), (0,0,255), 5)\n",
    "\tif draw_left:\n",
    "\t\tcv2.line(img, (left_x1, y1), (left_x2, y2), (0,0,255), 5)\n",
    "\tif draw_right and draw_left:\n",
    "\t\toverlay=img.copy()\n",
    "\t\tpts=np.array([[right_x1, y1],[right_x2, y2],[left_x2, y2],[left_x1, y1]],np.int32)\n",
    "\t\tpts=pts.reshape((-1,1,2))\n",
    "\t\tcv2.fillPoly(overlay,[pts],(0,255,0))\n",
    "\t\topacity=.2\n",
    "\t\tcv2.addWeighted(overlay, opacity, img, 1 - opacity, 0, img)\n",
    "\t\t\n",
    "\t\t\n",
    "\t\n",
    "\treturn(img)\n",
    "\n",
    "def region_of_interest(img, vertices):\n",
    "    \"\"\"\n",
    "    Applies an image mask.\n",
    "\n",
    "    Only keeps the region of the image defined by the polygon\n",
    "    formed from `vertices`. The rest of the image is set to black.\n",
    "    \"\"\"\n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)\n",
    "\n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "\n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color\n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "\n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "# run line detection pipeline\n",
    "def leer_vid():\n",
    "\t#1.- get frame from the video \n",
    "\tcap = cv2.VideoCapture('highway_right_solid_white_line_short.mp4')\n",
    "\twhile cap.isOpened():\n",
    "\t\tret, frame = cap.read()\n",
    "\t\tif ret:\n",
    "\t\t\tlec  = run_pipeline(frame)\n",
    "\t\telse:\n",
    "\t\t\tif not lec: \n",
    "\t\t\t\tprint(\"No frame available\")\n",
    "\t\t\t\tbreak\n",
    "\t\t\telif lec:\n",
    "\t\t\t\tprint(\"Video Finished\")\n",
    "\t\t\t\tbreak\n",
    "\t\t\t\n",
    "\t\t# wait for the user to press 'q' to exit \n",
    "\t\tif cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "\t\t\tbreak\n",
    "\t\t\t\n",
    "\tcap.release()\n",
    "\n",
    "# destroy windows to free memory\n",
    "\tcv2.destroyAllWindows()\n",
    "\treturn(None)\n",
    "def run_pipeline(img_colour):\n",
    "      \n",
    "    \n",
    "\t# 2. Convert from BGR to RGB then from RGB to greyscale\n",
    "    img_colour_rgb = cv2.cvtColor(img_colour, cv2.COLOR_BGR2RGB)\n",
    "    grey = cv2.cvtColor(img_colour_rgb, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "\t# 3.- Apply Gaussuan smoothing\n",
    "    kernel_size = (7,7)\n",
    "    blur_grey = cv2.GaussianBlur(grey, kernel_size, sigmaX=0, sigmaY=0)\n",
    "\n",
    "\t# 4.- Apply Canny edge detector\n",
    "    low_threshold = 10\n",
    "    high_threshold = 70\n",
    "    edges = cv2.Canny(blur_grey, low_threshold, high_threshold, apertureSize=3)\n",
    "\n",
    "\t# 5.- Define a polygon-shape like region of interest\n",
    "    img_shape = grey.shape\n",
    "\n",
    "    # uncomment the following lines when extracting lines around the whole image\n",
    "    '''\n",
    "    img_size = img_shape\n",
    "    bottom_left = (0, img_size[0])\n",
    "    top_left = (0, 0)\n",
    "    top_right = (img_size[1], 0)\n",
    "    bottom_right = (img_size[1], img_size[0])\n",
    "    '''\n",
    "\n",
    "\t# comment the following lines when extracting  lines around the whole image\n",
    "    bottom_left = (410, 850)\n",
    "    top_left = (820, 600)\n",
    "    top_right = (1200, 600)\n",
    "    bottom_right = (1650, 850)\n",
    "\n",
    "    # create a vertices array that will be used for the roi\n",
    "    vertices = np.array([[bottom_left,top_left, top_right, bottom_right]], dtype=np.int32)\n",
    "\n",
    "\t# 6.- Get a region of interest using the just created polygon. This will be\n",
    "\t#     used together with the Hough transform to obtain the estimated Hough lines\n",
    "    masked_edges = region_of_interest(edges, vertices)\n",
    "\n",
    "\t# 7.- Apply Hough transform for lane lines detection\n",
    "    rho = 1                       # distance resolution in pixels of the Hough grid\n",
    "    theta = np.pi/180             # angular resolution in radians of the Hough grid\n",
    "    threshold = 40                # minimum number of votes (intersections in Hough grid cell)\n",
    "    min_line_len = 5              # minimum number of pixels making up a line\n",
    "    max_line_gap = 450             # maximum gap in pixels between connectable line segments\n",
    "    line_image = np.copy(img_colour)*0   # creating a blank to draw lines on\n",
    "    hough_lines = cv2.HoughLinesP(masked_edges, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "##################3\n",
    "    \n",
    "    img_w_lines2 = draw_lines(img_colour_rgb.copy(),hough_lines)\n",
    "\n",
    "##########33\n",
    "\t# 8.- Visualise input and output images\n",
    "    img_colour_with_lines = img_colour_rgb.copy()\n",
    "    if hough_lines is not None: \n",
    "        for line in hough_lines:\n",
    "            for x1, y1, x2, y2 in line:\n",
    "                cv2.line(img_colour_with_lines, (x1, y1), (x2, y2), (0,255,0), 3)\n",
    "\n",
    "\t# visualise input and output images\n",
    "    #cv2.imshow(\"img colour rgb\",img_colour_rgb)\n",
    "    #cv2.imshow(\"blur grey\",blur_grey)\n",
    "    cv2.imshow(\"practica9\",img_w_lines2)\n",
    "    cv2.imshow(\"edges\",edges)\n",
    "    #cv2.imshow(\"img color w/lines\", img_colour_with_lines)\n",
    "    \n",
    "    return True\n",
    "def plt_vis():\n",
    "    plt.figure(1)\n",
    "    plt.imshow(img_colour_rgb)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.figure(2)\n",
    "    plt.imshow(blur_grey, cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.figure(3)\n",
    "    plt.imshow(edges, cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.figure(4)\n",
    "    plt.imshow(img_colour_with_lines)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "# fun pipeline\n",
    "#img_name = 'highway_frame_0001.png'\n",
    "#run_pipeline(img_name)\n",
    "global lec \n",
    "lec = False\n",
    "leer_vid()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El proceso seguido para detectar las líneas de la imagen por medio de la transformada de Hough es igual a la que nos muestra el profesor en las instrucciones de la imagen, lo que hicimos diferente fue como calcular la posición de las líneas que determinan el espacio del carril. Para esto primero definimos el area de interés y a esa área aplicamos la transformada de Hough. \n",
    "Una vez que ya generamos las líneas las separamos en las que están a la izquierda de la imagen y las que están a la derecha, tomando en cuenta el centro del área de interes y la pendiente de las líneas, sabemos que las del lado izquierdo tendrán pendiente positiva y las de la derecha negativa.\n",
    "Una vez separadas las líneas entre izquierda y derecha de cada uno de estos arreglos separamos las coordenadas x de las y para luego aplicar regresión lineal a estos puntos, de ste modo obtendremos la línea que mejor describa a todos nuestros puntos.\n",
    "Ya que tenemos la función de las líneas obtenemos los puntos inicial y final para dibujarlas sobre la imagen. Por último en una copia de la imagen se hace un polígono relleno con la funciòn fillPoly, luego se unen la original con la que tiene el polígono utilizando la función addWeighted, la que nos permite añadir la imagen del polígono con cierta transparencia.\n",
    "![title](edgesP9.png)\n",
    "![title](ev1P9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusiones \n",
    "\n",
    "#### Kassandra Dzuara Ibarra Ortiz \n",
    "Esta práctica en general me agrado que pudimos profundizar aún más en la práctica de detección de bordes mediante la detección de líneas utilizando transformadas de Hough, ya que esta te permite analizar y procesar una imagen en las que mediante una técnica de voting puede detectar líneas sin sensibilidad a ruidos en la imagen, aunque no me quedo 100% claro cómo es que votan tal cual los puntos para la detección de líneas si logre comprender cómo es que se analiza cada punto para saber si pertenece o no a un borde o línea. Creo que esta función en general será de mucha ayuda al momento de querer detectar objetos y detectar figuras al momento de querer guiar a nuestro carrito del proyecto final hacia su destino.\n",
    "\n",
    "#### Jesus Alejandro Ramirez Castañeda\n",
    "\n",
    "\n",
    "#### Alberto Jasiel Herrera Michel\n",
    "La detección de lineas por medio de la transformada de hough es un método bastante interesante, supongo que es bastante usado en los sistemas de navegación de vehículos no tripulados, pues en esencia le permite al vehículo conocer su entorno y en base a eso actuar. Como nos dijo el profesor, este fue la primer práctica de visión computacional ya que todas las demás fueron procesamiento de imagen, pero gracias a eso pudimos realizar esta práctica. \n",
    "Al igual que todos los demás métodos de opencv, la transformada hough facilita mucho las cosas, pues con una simple función y una serie de comandos pudimos obtener las lineas de la imagen que a mi parecer es algo bastante complicado-"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
