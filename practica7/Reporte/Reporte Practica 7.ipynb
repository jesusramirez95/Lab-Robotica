{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Universidad de Monterrey\n",
    "### División de Ingenierías\n",
    "### Lab - Robotics\n",
    "### Lab 7: Spatial Filtering\n",
    "#### Authors: Alberto Jasiel Herrera, Jesús Alejandro Ramírez & Kassandra Dzuara Ibarra.\n",
    "\n",
    "##### Objetivo  \n",
    "El objetivo de esta práctica es aprender los fundamentos básicos del filtrado y procesado de imágenes mediante el uso de correlaciones y convoluciones aplicadas a imágenes. También con esta práctica aprenderemos a utilizar las funciones de opencv para realizar filtrados y con ello podremos determinar el tipo de filtrado necesario para las distintas aplicaciones que lleguemos a realizar en un futuro.\n",
    "\n",
    "#### 3 Materiales \n",
    "Raspberry PI 3\n",
    "\n",
    "Pantalla y cable HDMI para visualizar la raspberry.\n",
    "\n",
    "Además, la Raspberry debe contar con el software pedido al inicio del laboratorio (opencv, python 3.5, Jupyter, ssh, entre otros).\n",
    "\n",
    "#### 4 Procedimiento \n",
    "#### 4.1 Fundamentos de filtrados\n",
    "El proceso de filtrado consiste en aplicar una transformación (generalmente conocida como T) a una imagen (f), específicamente la transformación se aplica al “vecindario” de un pixel de la imagen, este vecindario es un conjunto rectangular de píxeles cuyo centro es un pixel escogido arbitrariamente. Dado lo anterior podemos describir el filtrado con la siguiente expresión matemática:\n",
    "g(x,y)=T[f(x,y)]\n",
    "Donde (x,y) es el píxel seleccionado, para hacer el filtrado de la imagen se va moviendo el origen del vecindario por cada pixel de la imagen, pero este vecindario tiene que ser mucho más pequeño de la imagen.\n",
    "\n",
    "#### 4.2 Correlaciones y convoluciones\n",
    "Los conceptos de correlación y convolución son importantes cuando hablamos de flitrado espacial, ya que estos son métodos por lo cuales podemos aplicar un filtrado a lo largo de la imagen. Ambos métodos siguen la estructura que describimos en la sección 4.1, desplazar una matriz a lo largo de los pixeles de la imagen, sin embargo, tanto en correlación como en convolución se hace la suma de productos de los valores de la matriz con los del vecindario del pixel de origen. \n",
    "La única diferencia entre estos procesos es que en convolución primero se rota 180° la matriz de transformación.\n",
    "\n",
    "#### 4.3 Smoothing filters\n",
    "Opencv cuenta con la función cv2.filter2D() para realizar la convolución y correlación de una imagen. Sin embargo, para realizar la convolución tenemos que utilizar la función cv2.flip() primero.\n",
    "Lo que hace cv2.flip es rotar 180 grados la matriz de transformación que le demos como argumento, esta función tiene 2 argumentos de entrada, una matriz y un número, el número indica el tipo de flip que se hace 0 es horizontal, 1 vertical y -1 ambos. \n",
    "Y la función cv2.filter2D necesita 3 argumentos, la imagen o matriz objetivo, un -1 que es un parámetro de la salida y el kernel a aplicar, la salida de este es la suma de productos de la matriz y el kernel que le dimos con el desplazamiento del kernel por cada pixel de la imagen/matriz.\n",
    "Si aplicamos un kernel de 1x1 a la imagen sería 1/1[1] y la transformación se haría solo al pixel de origen, por lo que nos daría una imagen idéntica a la de entrada.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-2ae42ea1b0a1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m# read image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\tconvolve_image_with_kernel.py\n",
    "\t\n",
    "\tadd a description of your code here\n",
    "\n",
    "\tauthor: add your fullname \n",
    "\tdate created: add this info\n",
    "\tuniversidad de monterrey\n",
    "\"\"\"\n",
    "\n",
    "# import required libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# read image\n",
    "img_name = 'cavalo_motorizado.jpg'\n",
    "img = cv2.imread(img_name)\n",
    "\n",
    "# verify that image `img` exist\n",
    "if img is None:\n",
    "\tprint('ERROR: image ', img_name, 'could not be read')\n",
    "\texit()\n",
    "\n",
    "# define a kernel\n",
    "#kernel = np.ones((1,1),np.float32)\n",
    "kernel = np.ones((5,5), np.float32)/25\n",
    "#kernel\t = np.ones((13,13), np.float32)/169\n",
    "#kernel = np.ones((21,21), np.float32)/441\n",
    "#kernel = np.ones((31,31), np.float32)/961\n",
    "#kernelx = np.array([[1,2,1],[2,4,2],[1,2,1]], np.float32)/16\n",
    "dst_correlation = cv2.filter2D(img, -1, kernelx)\n",
    "\n",
    "# rotate kernel\n",
    "kernel_rotated = cv2.flip(kernelx, -1)\n",
    "dst_convolution = cv2.filter2D(img, -1, kernel_rotated)\n",
    "\n",
    "# plot input and convolved images\n",
    "plt.figure(1)\n",
    "plt.imshow(img)\n",
    "plt.title('Input image')\n",
    "plt.xticks([]) \n",
    "plt.yticks([])\n",
    "\n",
    "plt.figure(2)\n",
    "plt.imshow(dst_correlation)\n",
    "plt.title('Output image using a 3x3 averaging filter (correlation)')\n",
    "plt.xticks([]) \n",
    "plt.yticks([])\n",
    "\n",
    "plt.figure(3)\n",
    "plt.imshow(dst_convolution)\n",
    "plt.title('Output image using a 3x3 averaging filter (convolution)')\n",
    "plt.xticks([]) \n",
    "plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### al aplicar un kernel de 1x1 el resultado es el siguiente\n",
    "![title](kernel1x1.png)\n",
    "\n",
    "\n",
    "### continuamos con un kernel 5x5 (Default en la practica)\n",
    "![title](kernel5x5.png)\n",
    "\n",
    "### luego un kernel 13x13\n",
    "![title](13x13filter.png)\n",
    "\n",
    "### con un kernel 21x21\n",
    "![title](21x21kernel.png)\n",
    "\n",
    "### finalizamos esta parte con la matriz ![title](kernelx.gif) como kernel\n",
    "![title](3x3filter.png)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### 4.4 Difuminado\n",
    "Una alternativa para el procesamiento de imágenes es utilizando la función: \n",
    "cv2.blur()\n",
    "Para esto se aplica la siguiente función para el cálculo del kernel:\n",
    "\n",
    "![kernel](kernel2.png)\n",
    "\n",
    "La función de blur solo recibe como argumentos de entrada la imagen a transformar y el tamaño del kernel, con el tamaño del kernel la misma función determina el kernel normalizado.\n",
    "Lo que hace blur es aplicar un filtro pasa bajas a la imagen para eliminar ruido o bordes en la imagen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\tblur_image.py\n",
    "\t\n",
    "\tadd a description of your code here\n",
    "\n",
    "\tauthor: add your fullname \n",
    "\tdate created: add this info\n",
    "\tuniversidad de monterrey\n",
    "\"\"\"\n",
    "\n",
    "# import required libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# read image\n",
    "img_name = 'cavalo_motorizado.jpg'\n",
    "img = cv2.imread(img_name)\n",
    "\n",
    "# verify that image `img` exist\n",
    "if img is None:\n",
    "\tprint('ERROR: image ', img_name, 'could not be read')\n",
    "\texit()\n",
    "\n",
    "# blur image using `cv2.blur()`\n",
    "kernel_size = (11,11)\n",
    "blurred_image = cv2.blur(img, kernel_size)\n",
    "\n",
    "# plot input and blurred images\n",
    "plt.figure(1)\n",
    "plt.imshow(img)\n",
    "plt.title('Input image')\n",
    "plt.xticks([]) \n",
    "plt.yticks([])\n",
    "\n",
    "plt.figure(2)\n",
    "plt.imshow(blurred_image)\n",
    "plt.title('Output image using cv2.blur(%i,%i)' % (kernel_size[0], kernel_size[1]))\n",
    "plt.xticks([]) \n",
    "plt.yticks([])\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### resultado de filtro Blur 11x11\n",
    "![imageblur](blur11x11.png)\n",
    "\n",
    "\n",
    "#### 4.5 Difuminado Gaussiano\n",
    " \n",
    "Otra alternativa para difuminar una imagen es utilizando el difuminado gaussiano el cual se utiliza con la función: \n",
    "cv2.GaussianBlur()\n",
    "Para esto en el código se utilizaran diferentes tamaños de kernel utilizando la ecuación a continuación: \n",
    "![kernel](eq2.gif)\n",
    "en donde se utiliza la desviación estándar con variables x y y como números enteros. Para entender la importancia del valor de la desviación estándar hay que recordar que la función gaussiana tiene forma de campana y el valor de la desviación estándar define el ancho de dicha campana. \n",
    "La función GaussianBlur recibe de argumentos de entrada la imagen a aplicar el filtro, el tamaño del kernel y un parámetro numérico que indica la desviación en X y Y. A diferencia de la función Blur, esta utiliza un kernel Gaussiano.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\tgaussian_blur_image.py\n",
    "\t\n",
    "\tadd a description of your code here\n",
    "\n",
    "\tauthor: add your fullname \n",
    "\tdate created: add this info\n",
    "\tuniversidad de monterrey\n",
    "\"\"\"\n",
    "\n",
    "# import required libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# read image\n",
    "img_name = 'cavalo_motorizado.jpg'\n",
    "img = cv2.imread(img_name)\n",
    "\n",
    "# verify that image `img` exist\n",
    "if img is None:\n",
    "\tprint('ERROR: image ', img_name, 'could not be read')\n",
    "\texit()\n",
    "\n",
    "# blur image using `cv2.blur()`\n",
    "kernel_size = (21,21)\n",
    "blurred_image = cv2.GaussianBlur(img, kernel_size, 0)\n",
    "\n",
    "# plot input and blurred images\n",
    "plt.figure(1)\n",
    "plt.imshow(img)\n",
    "plt.title('Input image')\n",
    "plt.xticks([]) \n",
    "plt.yticks([])\n",
    "\n",
    "plt.figure(2)\n",
    "plt.imshow(blurred_image)\n",
    "plt.title('Output image using cv2.blur(%i,%i)' % (kernel_size[0], kernel_size[1]))\n",
    "plt.xticks([]) \n",
    "plt.yticks([])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resultado Kernel 21x21 Gaussian Blur\n",
    "![title](gaussblur.png)\n",
    "\n",
    "#### 4.6 Medio difuminado \n",
    " En esta sección se utilizará una función con el propósito de filtrar el ruido de una imagen, para entender bien el funcionamiento de esta instrucción se utilizara un código que simule ruido “Salt & pepper” para después usar esta instrucción para eliminar el ruido:\n",
    "cv2.medianBlur()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\tmedian_filter_for_noise_removal.py\n",
    "\t\n",
    "\tadd a description of your code here\n",
    "\n",
    "\tauthor: add your fullname \n",
    "\tdate created: add this info\n",
    "\tuniversidad de monterrey\n",
    "\"\"\"\n",
    "\n",
    "# import required libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# read image\n",
    "img_name = 'cavalo_motorizado.jpg'\n",
    "img = cv2.imread(img_name)\n",
    "\n",
    "# verify that image `img` exist\n",
    "if img is None:\n",
    "\tprint('ERROR: image ', img_name, 'could not be read')\n",
    "\texit()\n",
    "\n",
    "# define level of salt & pepper noise\n",
    "s_vs_p = 0.2\t\t\t\t\t\t\t\t\n",
    "amount = 0.07\t\t\t\t\t\t\t\t# <--- change this value\n",
    "\n",
    "# create a copy of input image\n",
    "out = img.copy()\n",
    "\n",
    "# Generate Salt '1' noise\n",
    "num_salt = np.ceil(amount * img.size * s_vs_p)\n",
    "coords = [np.random.randint(0, i - 1, int(num_salt)) for i in img.shape]\n",
    "out[coords] = 255\n",
    "        \n",
    "# Generate Pepper '0' noise\n",
    "num_pepper = np.ceil(amount* img.size * (1. - s_vs_p))\n",
    "coords = [np.random.randint(0, i - 1, int(num_pepper)) for i in img.shape]\n",
    "out[coords] = 0\n",
    "\n",
    "# apply cv2.medianBlur() for noise removal\n",
    "ksize = 7\t\t\t\t\t\t\t\t# <--- change this value\n",
    "img_median = cv2.medianBlur(out, ksize)\n",
    "\n",
    "# plot input and blurred images\n",
    "plt.figure(1)\n",
    "plt.imshow(img)\n",
    "plt.title('Input image')\n",
    "plt.xticks([]) \n",
    "plt.yticks([])\n",
    "\n",
    "plt.figure(2)\n",
    "plt.imshow(out)\n",
    "plt.title('Noise')\n",
    "plt.xticks([]) \n",
    "plt.yticks([])\n",
    "\n",
    "plt.figure(3)\n",
    "plt.imshow(img_median)\n",
    "plt.title('Noise Filtered')\n",
    "plt.xticks([]) \n",
    "plt.yticks([])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "###### A continuación se muestran las imágenes de salida después de modificar lo parámetros de amount y ksize, donde amount modifica la cantidad de ruido y ksize el tamaño del kernel.\n",
    "\n",
    "![medianBlur](median_blur.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 Conclusiones \n",
    "\n",
    "#### 5.1 Kassandra Dzuara Ibarra Ortiz \n",
    "En esta practica aprendi cosas nuevas y la teoria detrás de esta, para comenzar a grandes rasgos esta práctica trata de como filtrar una imagen mediante diferentes métodos y de esta forma crear una imagen nueva pero difuminada de la original. Sin embargo, aunque suena sencillo para poder manipular correctamente el filtrado de cada imagen se tiene que calcular el kernel. Además de esto una de las cosas mas interesantes fue el filtrado de ruido ya que es de las funciones que son muy útiles al momento de desarrollar una aplicación que depende de la visión del sistema.\n",
    "\n",
    "#### 5.2 Jesus Alejandro Ramirez Castañeda\n",
    "Gracias a esta pràctica nos acercamos mas a nuestra meta de poder hacer que el vehìculo pueda navegar hacia ciertos objetivos afdemas que el filtrado de imagenes en general es muy ùtil puesto que nunca se sabe cuando sera necesario hacer uso de estos, todos estos filtros son muy ùtiles ya que al tener distintos podemos utilizar aquel que se ajuste mas a nuestras necesidades, y de esta forma prevenir que factores como la calidad de la càmara o de la fotografìa afecte a nuestro porceso, ademas ya que hemos visto la manera en la que el kernel afecta a las imagenes esto tambien nos ayuda para poder escoger el que mas se ajuste a nuestro proyecto, tambìen pienso que esta pràctoca nos ayuda a reforzar cierto conocimientos que asdquirimos a lo largo de la carrera y asì tener un panorama mas amplio de lo que podemos hacer con estos temas. \n",
    "\n",
    "#### 5.3 Alberto Jasiel Herrera Michel\n",
    "El filtrado de imágenes es un proceso muy importante en las aplicaciones de campo, ya que, se está trabajando en un ambiente dinámico donde podemos preveer muy pocas cosas y las distintas condiciones ambientales pueden provocar que obtengamos imágenes que por sí solas no son aptas para ser procesadas y utilizadas en la aplicación. Sin embargo, si conocemos cuales son el ruido o factores que afectarán a la obtención de imágenes podemos aplicar filtros como los vistos en esta práctica para obtener imágenes óptimas de otras que pensábamos no servirían.\n",
    "Algo de lo que me pude dar cuenta respecto al kernel, es que entre más grande sea el kernel más contacto tendrá con la imagen al realizar el filtrado, ya que el kernel afectará varias veces a los mismos pixeles dependiendo de su tamaño.\n",
    "Creo que este proceso es preliminar a casi cualquier aplicación ya que siempre deseamos eliminar el ruido o imperfecciones de la imagen antes de procesarla. \n",
    "Por último creo que esta práctica se parece un poco a la anterior, en el aspecto de que tenemos que buscar el filtro adecuado para nuestra aplicación, es por eso que se nos muestran distintos tipos de filtros.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
